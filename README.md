# DSCI-531-Project

In terms of data privacy, the medical field is one of the most invasive, yet highly-regulated fields there is. HIPAA data, also known as PHI (protected health information), is data that is regulated and meant to be kept private for each patient. Among some of the attributes that fall under PHI are demographic information such as age and gender. As machine learning and AI models become more prevalent in the medical field, they can be used to evaluate a patient's risk for certain conditions such as a stroke or heart disease. Because of the regulations set in place within the medical field, there is a plethora of PHI that researchers use in models meant to predict these dangerous events. However, our group wants to tackle an important question: is this PHI data necessary, and can it lead to model bias? Looking into age and gender specifically, there are historical biases that can lead to research problems that will be overlooked without careful experimentation applied to future research. For example, females make up around 50% of the population, but the large majority of medical data/research is composed of males. This means without paying careful attention to training data composition, you could be biasing your model's outputs towards either gender (in most general studies this would be biased to be more accurate for males at the cost of performance for females). You can also see further bias in the medical field considering a large majority of patients tend to be older, again leading to a skewed representation of the population in most data that will need to be considered.